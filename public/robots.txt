# BPS Dynamic Website Robots.txt
# Allow all web crawlers to access all content
User-agent: *
Allow: /

# Sitemap location (complete site map with all pages)
Sitemap: https://bpsdynamic.com/sitemap.xml

# Last updated: 2023-11-01
# Generated with BPS Dynamic sitemap generator
# To update this file, run: npm run generate-sitemap
User-agent: *
Allow: /

# Sitemaps
Sitemap: https://bpsdynamic.com/sitemap.xml

# Disallow patterns
Disallow: /api/
Disallow: /admin/
Disallow: /private/

# Crawl delay for certain bots
User-agent: AdsBot-Google
Crawl-delay: 1

User-agent: Baiduspider
Crawl-delay: 5
